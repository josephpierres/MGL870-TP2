{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation des bibliothèques nécessaires\n",
    "Importer les bibliothèques nécessaires, y compris pandas, numpy, scikit-learn, et matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve\n",
    "from sklearn.utils import resample\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set seaborn style for plots\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement des données\n",
    "Charger les fichiers CSV HDFS_occurence_matrix_HDFS_train.csv, HDFS_occurence_matrix_HDFS_valid.csv, et HDFS_occurence_matrix_HDFS_test.csv dans des DataFrames pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    BlockId    Label  Type    Time   Date  E1  E2  E3  E4  E5  \\\n",
      "0   blk_-100000266894974466  Success     0   20106  81110   3   3   3   3   3   \n",
      "1  blk_-1000014584150379967  Success     0   15117  81110   3   3   3   3   3   \n",
      "2  blk_-1000028658773048709  Success     0  221431  81110   3   3   3   3   0   \n",
      "3  blk_-1000054577281647820  Success     0   12444  81110   3   3   3   3   3   \n",
      "4  blk_-1000083860370843431  Success     0  211524  81109   3   3   3   3   3   \n",
      "\n",
      "   ...  E20  E21  E22  E23  E24  E25  E26  E27  E28  E29  \n",
      "0  ...    0    0    0    0    0    0    0    0    0    0  \n",
      "1  ...    0    0    0    0    0    0    0    0    0    0  \n",
      "2  ...    0    0    0    0    0    0    0    0    0    0  \n",
      "3  ...    0    0    0    0    0    0    0    0    0    0  \n",
      "4  ...    0    0    0    0    0    0    0    0    0    0  \n",
      "\n",
      "[5 rows x 34 columns]\n",
      "                    BlockId    Label  Type   Time   Date  E1  E2  E3  E4  E5  \\\n",
      "0  blk_-1000028658773048709  Success     0  44331  81111   0   0   0   0   3   \n",
      "1   blk_-100004553717737248  Success     0  43200  81111   3   3   3   3   0   \n",
      "2  blk_-1000057191487947536  Success     0  71152  81111   3   3   3   3   0   \n",
      "3  blk_-1000304635958160643  Success     0  63152  81111   3   3   3   3   3   \n",
      "4  blk_-1000350290085528508  Success     0  44343  81111   0   0   0   0   3   \n",
      "\n",
      "   ...  E20  E21  E22  E23  E24  E25  E26  E27  E28  E29  \n",
      "0  ...    0    0    0    0    0    0    0    0    0    0  \n",
      "1  ...    0    0    0    0    0    0    0    0    0    0  \n",
      "2  ...    0    0    0    0    0    0    0    0    0    0  \n",
      "3  ...    0    0    0    0    0    0    0    0    0    0  \n",
      "4  ...    0    0    0    0    0    0    0    0    0    0  \n",
      "\n",
      "[5 rows x 34 columns]\n",
      "                    BlockId    Label  Type   Time   Date  E1  E2  E3  E4  E5  \\\n",
      "0  blk_-1000002529962039464  Success     0  94452  81111   3   3   3   3   0   \n",
      "1  blk_-1000007292892887521  Success     0  94715  81111   3   3   3   3   0   \n",
      "2  blk_-1000057191487947536  Success     0  85911  81111   0   0   0   0   3   \n",
      "3  blk_-1000520838662594670  Success     0  75621  81111   0   0   0   0   3   \n",
      "4   blk_-100054792011350725  Success     0  84654  81111   3   3   3   3   0   \n",
      "\n",
      "   ...  E20  E21  E22  E23  E24  E25  E26  E27  E28  E29  \n",
      "0  ...    0    0    0    0    0    0    0    0    0    0  \n",
      "1  ...    0    0    0    0    0    0    0    0    0    0  \n",
      "2  ...    0    0    0    0    0    0    0    0    0    0  \n",
      "3  ...    0    0    0    0    0    0    0    0    0    0  \n",
      "4  ...    0    0    0    0    0    0    0    0    0    0  \n",
      "\n",
      "[5 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "# Chargement des données\n",
    "train_df = pd.read_csv('HDFS_results/Event_occurence_matrix_HDFS_train.csv')\n",
    "valid_df = pd.read_csv('HDFS_results/Event_occurence_matrix_HDFS_valid.csv')\n",
    "test_df = pd.read_csv('HDFS_results/Event_occurence_matrix_HDFS_test.csv')\n",
    "\n",
    "# Afficher les premières lignes des DataFrames pour vérifier le chargement\n",
    "print(train_df.head())\n",
    "print(valid_df.head())\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse des variables et traitement des corrélations\n",
    "Calculer la matrice de corrélation sur les variables indépendantes dans l'ensemble d'entraînement. Identifier et supprimer les variables fortement corrélées (corrélation > 0,9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse des variables et traitement des corrélations\n",
    "\n",
    "# Calcul de la matrice de corrélation sur les variables indépendantes\n",
    "correlation_matrix = train_df.drop(columns=['BlockId', 'Label', 'Type', 'Time', 'Date'])\n",
    "\n",
    "# Affichage de la matrice de corrélation\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.title('Matrice de corrélation des variables indépendantes')\n",
    "plt.show()\n",
    "\n",
    "# Identification des variables fortement corrélées (corrélation > 0,9)\n",
    "high_corr_var = set()\n",
    "threshold = 0.9\n",
    "\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > threshold:\n",
    "            colname = correlation_matrix.columns[i]\n",
    "            high_corr_var.add(colname)\n",
    "\n",
    "# Suppression des variables fortement corrélées\n",
    "train_df_reduced = train_df.drop(columns=high_corr_var)\n",
    "valid_df_reduced = valid_df.drop(columns=high_corr_var)\n",
    "test_df_reduced = test_df.drop(columns=high_corr_var)\n",
    "\n",
    "# Affichage des variables supprimées\n",
    "print(f\"Variables supprimées en raison d'une forte corrélation: {high_corr_var}\")\n",
    "\n",
    "# Affichage des premières lignes des DataFrames réduits pour vérifier les modifications\n",
    "print(train_df_reduced.head())\n",
    "print(valid_df_reduced.head())\n",
    "print(test_df_reduced.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création des échantillons avec bootstrap\n",
    "Utiliser le bootstrap pour créer des échantillons de l'ensemble d'entraînement. Chaque échantillon a la même taille que l'ensemble d'entraînement d'origine (avec remplacement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des échantillons avec bootstrap\n",
    "\n",
    "# Définir le nombre d'échantillons bootstrap\n",
    "n_bootstrap_samples = 100\n",
    "\n",
    "# Initialiser une liste pour stocker les échantillons bootstrap\n",
    "bootstrap_samples = []\n",
    "\n",
    "# Créer des échantillons bootstrap\n",
    "for _ in range(n_bootstrap_samples):\n",
    "    bootstrap_sample = resample(train_df_reduced, replace=True, n_samples=len(train_df_reduced), random_state=42)\n",
    "    bootstrap_samples.append(bootstrap_sample)\n",
    "\n",
    "# Afficher le nombre d'échantillons bootstrap créés\n",
    "print(f\"Nombre d'échantillons bootstrap créés: {len(bootstrap_samples)}\")\n",
    "\n",
    "# Afficher les premières lignes du premier échantillon bootstrap pour vérifier\n",
    "print(bootstrap_samples[0].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modélisation et validation\n",
    "Pour chaque échantillon bootstrap, entraîner un modèle de régression logistique sur l'ensemble d'entraînement. Valider ce modèle sur un ensemble de validation distinct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modélisation et validation\n",
    "\n",
    "# Initialiser les listes pour stocker les performances des modèles\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "roc_auc_list = []\n",
    "\n",
    "# Séparer les features et la cible pour l'ensemble de validation\n",
    "X_valid = valid_df_reduced.drop(columns=['target'])\n",
    "y_valid = valid_df_reduced['target']\n",
    "\n",
    "# Pour chaque échantillon bootstrap, entraîner un modèle de régression logistique et valider\n",
    "for bootstrap_sample in bootstrap_samples:\n",
    "    # Séparer les features et la cible pour l'échantillon bootstrap\n",
    "    X_train_bootstrap = bootstrap_sample.drop(columns=['target'])\n",
    "    y_train_bootstrap = bootstrap_sample['target']\n",
    "    \n",
    "    # Entraîner le modèle de régression logistique\n",
    "    model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    model.fit(X_train_bootstrap, y_train_bootstrap)\n",
    "    \n",
    "    # Prédire sur l'ensemble de validation\n",
    "    y_pred = model.predict(X_valid)\n",
    "    y_pred_proba = model.predict_proba(X_valid)[:, 1]\n",
    "    \n",
    "    # Calculer les métriques de performance\n",
    "    accuracy_list.append(accuracy_score(y_valid, y_pred))\n",
    "    precision_list.append(precision_score(y_valid, y_pred))\n",
    "    recall_list.append(recall_score(y_valid, y_pred))\n",
    "    f1_list.append(f1_score(y_valid, y_pred))\n",
    "    roc_auc_list.append(roc_auc_score(y_valid, y_pred_proba))\n",
    "\n",
    "# Afficher les performances moyennes\n",
    "print(f\"Accuracy moyenne: {np.mean(accuracy_list):.4f}\")\n",
    "print(f\"Précision moyenne: {np.mean(precision_list):.4f}\")\n",
    "print(f\"Rappel moyen: {np.mean(recall_list):.4f}\")\n",
    "print(f\"F1-Score moyen: {np.mean(f1_list):.4f}\")\n",
    "print(f\"AUC-ROC moyen: {np.mean(roc_auc_list):.4f}\")\n",
    "\n",
    "# Afficher les performances des modèles sous forme de boxplots\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(2, 3, 1)\n",
    "sns.boxplot(data=accuracy_list)\n",
    "plt.title('Accuracy')\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "sns.boxplot(data=precision_list)\n",
    "plt.title('Précision')\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "sns.boxplot(data=recall_list)\n",
    "plt.title('Rappel')\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "sns.boxplot(data=f1_list)\n",
    "plt.title('F1-Score')\n",
    "\n",
    "plt.subplot(2, 3, 5)\n",
    "sns.boxplot(data=roc_auc_list)\n",
    "plt.title('AUC-ROC')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Répétition du processus\n",
    "Répéter les étapes de création d'échantillons bootstrap et de modélisation un nombre défini de fois. Stocker les performances (Précision, Rappel et AUC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Répétition du processus\n",
    "\n",
    "# Initialiser les listes pour stocker les performances des modèles\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "roc_auc_list = []\n",
    "\n",
    "# Définir le nombre de répétitions\n",
    "n_repetitions = 100\n",
    "\n",
    "# Séparer les features et la cible pour l'ensemble de validation\n",
    "X_valid = valid_df_reduced.drop(columns=['target'])\n",
    "y_valid = valid_df_reduced['target']\n",
    "\n",
    "# Répéter les étapes de création d'échantillons bootstrap et de modélisation\n",
    "for _ in range(n_repetitions):\n",
    "    # Créer un échantillon bootstrap\n",
    "    bootstrap_sample = resample(train_df_reduced, replace=True, n_samples=len(train_df_reduced), random_state=42)\n",
    "    \n",
    "    # Séparer les features et la cible pour l'échantillon bootstrap\n",
    "    X_train_bootstrap = bootstrap_sample.drop(columns=['target'])\n",
    "    y_train_bootstrap = bootstrap_sample['target']\n",
    "    \n",
    "    # Entraîner le modèle de régression logistique\n",
    "    model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    model.fit(X_train_bootstrap, y_train_bootstrap)\n",
    "    \n",
    "    # Prédire sur l'ensemble de validation\n",
    "    y_pred = model.predict(X_valid)\n",
    "    y_pred_proba = model.predict_proba(X_valid)[:, 1]\n",
    "    \n",
    "    # Calculer les métriques de performance\n",
    "    accuracy_list.append(accuracy_score(y_valid, y_pred))\n",
    "    precision_list.append(precision_score(y_valid, y_pred))\n",
    "    recall_list.append(recall_score(y_valid, y_pred))\n",
    "    f1_list.append(f1_score(y_valid, y_pred))\n",
    "    roc_auc_list.append(roc_auc_score(y_valid, y_pred_proba))\n",
    "\n",
    "# Afficher les performances moyennes\n",
    "print(f\"Accuracy moyenne: {np.mean(accuracy_list):.4f}\")\n",
    "print(f\"Précision moyenne: {np.mean(precision_list):.4f}\")\n",
    "print(f\"Rappel moyen: {np.mean(recall_list):.4f}\")\n",
    "print(f\"F1-Score moyen: {np.mean(f1_list):.4f}\")\n",
    "print(f\"AUC-ROC moyen: {np.mean(roc_auc_list):.4f}\")\n",
    "\n",
    "# Afficher les performances des modèles sous forme de boxplots\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(2, 3, 1)\n",
    "sns.boxplot(data=accuracy_list)\n",
    "plt.title('Accuracy')\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "sns.boxplot(data=precision_list)\n",
    "plt.title('Précision')\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "sns.boxplot(data=recall_list)\n",
    "plt.title('Rappel')\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "sns.boxplot(data=f1_list)\n",
    "plt.title('F1-Score')\n",
    "\n",
    "plt.subplot(2, 3, 5)\n",
    "sns.boxplot(data=roc_auc_list)\n",
    "plt.title('AUC-ROC')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Évaluation finale sur le test\n",
    "Appliquer le meilleur modèle sur l'ensemble de test. Calculer la matrice de confusion et des métriques comme l'accuracy, la précision, le rappel, le F1-Score, et l'AUC-ROC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluation finale sur le test\n",
    "\n",
    "# Séparer les features et la cible pour l'ensemble de test\n",
    "X_test = test_df_reduced.drop(columns=['target'])\n",
    "y_test = test_df_reduced['target']\n",
    "\n",
    "# Entraîner le meilleur modèle (Régression logistique) sur l'ensemble d'entraînement complet\n",
    "best_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "best_model.fit(train_df_reduced.drop(columns=['target']), train_df_reduced['target'])\n",
    "\n",
    "# Prédire sur l'ensemble de test\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculer les métriques de performance\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "precision_test = precision_score(y_test, y_test_pred)\n",
    "recall_test = recall_score(y_test, y_test_pred)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "roc_auc_test = roc_auc_score(y_test, y_test_pred_proba)\n",
    "\n",
    "# Afficher les métriques de performance\n",
    "print(f\"Accuracy sur le test: {accuracy_test:.4f}\")\n",
    "print(f\"Précision sur le test: {precision_test:.4f}\")\n",
    "print(f\"Rappel sur le test: {recall_test:.4f}\")\n",
    "print(f\"F1-Score sur le test: {f1_test:.4f}\")\n",
    "print(f\"AUC-ROC sur le test: {roc_auc_test:.4f}\")\n",
    "\n",
    "# Calculer la matrice de confusion\n",
    "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "# Afficher la matrice de confusion\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap='Blues', xticklabels=['Classe 0', 'Classe 1'], yticklabels=['Classe 0', 'Classe 1'])\n",
    "plt.xlabel('Prédiction')\n",
    "plt.ylabel('Réalité')\n",
    "plt.title('Matrice de confusion')\n",
    "plt.show()\n",
    "\n",
    "# Tracer la courbe ROC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_test_pred_proba)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'AUC-ROC = {roc_auc_test:.4f}')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('Taux de faux positifs (FPR)')\n",
    "plt.ylabel('Taux de vrais positifs (TPR)')\n",
    "plt.title('Courbe ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application à d'autres algorithmes (Random Forest)\n",
    "Reprendre les étapes de modélisation et de validation pour un Random Forest. Comparer les performances des deux modèles sur les mêmes métriques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application à d'autres algorithmes (Random Forest)\n",
    "\n",
    "# Initialiser les listes pour stocker les performances des modèles Random Forest\n",
    "rf_accuracy_list = []\n",
    "rf_precision_list = []\n",
    "rf_recall_list = []\n",
    "rf_f1_list = []\n",
    "rf_roc_auc_list = []\n",
    "\n",
    "# Pour chaque échantillon bootstrap, entraîner un modèle Random Forest et valider\n",
    "for bootstrap_sample in bootstrap_samples:\n",
    "    # Séparer les features et la cible pour l'échantillon bootstrap\n",
    "    X_train_bootstrap = bootstrap_sample.drop(columns=['target'])\n",
    "    y_train_bootstrap = bootstrap_sample['target']\n",
    "    \n",
    "    # Entraîner le modèle Random Forest\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train_bootstrap, y_train_bootstrap)\n",
    "    \n",
    "    # Prédire sur l'ensemble de validation\n",
    "    y_pred = rf_model.predict(X_valid)\n",
    "    y_pred_proba = rf_model.predict_proba(X_valid)[:, 1]\n",
    "    \n",
    "    # Calculer les métriques de performance\n",
    "    rf_accuracy_list.append(accuracy_score(y_valid, y_pred))\n",
    "    rf_precision_list.append(precision_score(y_valid, y_pred))\n",
    "    rf_recall_list.append(recall_score(y_valid, y_pred))\n",
    "    rf_f1_list.append(f1_score(y_valid, y_pred))\n",
    "    rf_roc_auc_list.append(roc_auc_score(y_valid, y_pred_proba))\n",
    "\n",
    "# Afficher les performances moyennes pour Random Forest\n",
    "print(f\"Random Forest - Accuracy moyenne: {np.mean(rf_accuracy_list):.4f}\")\n",
    "print(f\"Random Forest - Précision moyenne: {np.mean(rf_precision_list):.4f}\")\n",
    "print(f\"Random Forest - Rappel moyen: {np.mean(rf_recall_list):.4f}\")\n",
    "print(f\"Random Forest - F1-Score moyen: {np.mean(rf_f1_list):.4f}\")\n",
    "print(f\"Random Forest - AUC-ROC moyen: {np.mean(rf_roc_auc_list):.4f}\")\n",
    "\n",
    "# Afficher les performances des modèles Random Forest sous forme de boxplots\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(2, 3, 1)\n",
    "sns.boxplot(data=rf_accuracy_list)\n",
    "plt.title('Random Forest - Accuracy')\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "sns.boxplot(data=rf_precision_list)\n",
    "plt.title('Random Forest - Précision')\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "sns.boxplot(data=rf_recall_list)\n",
    "plt.title('Random Forest - Rappel')\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "sns.boxplot(data=rf_f1_list)\n",
    "plt.title('Random Forest - F1-Score')\n",
    "\n",
    "plt.subplot(2, 3, 5)\n",
    "sns.boxplot(data=rf_roc_auc_list)\n",
    "plt.title('Random Forest - AUC-ROC')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Évaluation finale sur le test pour Random Forest\n",
    "\n",
    "# Entraîner le meilleur modèle Random Forest sur l'ensemble d'entraînement complet\n",
    "best_rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "best_rf_model.fit(train_df_reduced.drop(columns=['target']), train_df_reduced['target'])\n",
    "\n",
    "# Prédire sur l'ensemble de test\n",
    "y_test_pred_rf = best_rf_model.predict(X_test)\n",
    "y_test_pred_proba_rf = best_rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculer les métriques de performance pour Random Forest\n",
    "accuracy_test_rf = accuracy_score(y_test, y_test_pred_rf)\n",
    "precision_test_rf = precision_score(y_test, y_test_pred_rf)\n",
    "recall_test_rf = recall_score(y_test, y_test_pred_rf)\n",
    "f1_test_rf = f1_score(y_test, y_test_pred_rf)\n",
    "roc_auc_test_rf = roc_auc_score(y_test, y_test_pred_proba_rf)\n",
    "\n",
    "# Afficher les métriques de performance pour Random Forest\n",
    "print(f\"Random Forest - Accuracy sur le test: {accuracy_test_rf:.4f}\")\n",
    "print(f\"Random Forest - Précision sur le test: {precision_test_rf:.4f}\")\n",
    "print(f\"Random Forest - Rappel sur le test: {recall_test_rf:.4f}\")\n",
    "print(f\"Random Forest - F1-Score sur le test: {f1_test_rf:.4f}\")\n",
    "print(f\"Random Forest - AUC-ROC sur le test: {roc_auc_test_rf:.4f}\")\n",
    "\n",
    "# Calculer la matrice de confusion pour Random Forest\n",
    "conf_matrix_rf = confusion_matrix(y_test, y_test_pred_rf)\n",
    "\n",
    "# Afficher la matrice de confusion pour Random Forest\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix_rf, annot=True, fmt=\"d\", cmap='Blues', xticklabels=['Classe 0', 'Classe 1'], yticklabels=['Classe 0', 'Classe 1'])\n",
    "plt.xlabel('Prédiction')\n",
    "plt.ylabel('Réalité')\n",
    "plt.title('Random Forest - Matrice de confusion')\n",
    "plt.show()\n",
    "\n",
    "# Tracer la courbe ROC pour Random Forest\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_test_pred_proba_rf)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_rf, tpr_rf, color='blue', lw=2, label=f'Random Forest AUC-ROC = {roc_auc_test_rf:.4f}')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('Taux de faux positifs (FPR)')\n",
    "plt.ylabel('Taux de vrais positifs (TPR)')\n",
    "plt.title('Random Forest - Courbe ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
